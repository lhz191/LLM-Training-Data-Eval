#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM Training Data Evaluation - ç»Ÿä¸€è¯„ä¼°å…¥å£

ç»Ÿä¸€çš„å‘½ä»¤è¡Œå…¥å£ï¼Œå¯ä»¥è°ƒç”¨ä»»æ„æ¨¡æ€çš„è¯„ä¼°ã€‚

Usage:
    # æ ¼å¼æ£€æŸ¥
    python -m common.evaluate --modality api --dataset toolbench --metric format
    python -m common.evaluate --modality gui --dataset mind2web --metric format
    python -m common.evaluate --modality math --dataset lila --metric format
    
    # å¯æ‰§è¡Œæ€§æ£€æŸ¥
    python -m common.evaluate --modality api --dataset toolbench --metric executability
    python -m common.evaluate --modality gui --dataset mind2web --metric static
    
    # åŠ¨æ€æ£€æŸ¥
    python -m common.evaluate --modality api --dataset toolbench --metric dynamic
    python -m common.evaluate --modality gui --dataset mind2web --metric dynamic
    
    # Math ç‰¹æœ‰
    python -m common.evaluate --modality math --dataset lila --metric validity
    
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é€‰é¡¹
    python -m common.evaluate --list
"""

import sys
import os
import argparse
import importlib
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)


# =============================================================================
# æ¨¡æ€åˆ°æ¨¡å—çš„æ˜ å°„
# =============================================================================

MODALITY_MODULES = {
    'api': 'modalities.Agent_Data.api_agent_eval',
    'gui': 'modalities.Agent_Data.text_gui_agent_eval',
    'math': 'modalities.Symbolic_and_Logical_Data.math_eval',
    'image': 'modalities.Vision_Language_Data.image_text_eval',
    'video': 'modalities.Vision_Language_Data.video_text_eval',
}

MODALITY_DESCRIPTIONS = {
    'api': 'API Agent (ToolBench, xLAM)',
    'gui': 'GUI Agent (Mind2Web, WebShop, WebLINX)',
    'math': 'Math/Symbolic (LILA, OpenMath)',
    'image': 'Image-Text',
    'video': 'Video-Text',
}


# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def list_all():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡æ€å’Œæ•°æ®é›†"""
    print("=" * 60)
    print("LLM Training Data Evaluation - Available Options")
    print("=" * 60)
    
    for modality, desc in MODALITY_DESCRIPTIONS.items():
        module_path = MODALITY_MODULES[modality]
        print(f"\nğŸ“ {modality}: {desc}")
        print(f"   Module: {module_path}")
        
        # å°è¯•å¯¼å…¥å¹¶åˆ—å‡ºæ•°æ®é›†
        try:
            # å°è¯•å¯¼å…¥ scripts/run_full_test.py è·å– DATASETS
            run_module = importlib.import_module(f'{module_path}.scripts.run_full_test')
            if hasattr(run_module, 'DATASETS'):
                datasets = list(run_module.DATASETS.keys())
                print(f"   Datasets: {', '.join(datasets)}")
        except (ImportError, ModuleNotFoundError):
            print(f"   Datasets: (module not found)")


def run_evaluation(modality: str, dataset: str, metric: str, **kwargs):
    """
    è¿è¡Œè¯„ä¼°
    
    Args:
        modality: æ¨¡æ€
        dataset: æ•°æ®é›†
        metric: è¯„ä¼°æŒ‡æ ‡
        **kwargs: å…¶ä»–å‚æ•°
    """
    if modality not in MODALITY_MODULES:
        print(f"âŒ Unknown modality: {modality}")
        print(f"   Available: {', '.join(MODALITY_MODULES.keys())}")
        sys.exit(1)
    
    module_path = MODALITY_MODULES[modality]
    
    print("=" * 60)
    print(f"Running: {modality} / {dataset} / {metric}")
    print("=" * 60)
    
    try:
        # å¯¼å…¥å¯¹åº”æ¨¡æ€çš„ run_full_test æ¨¡å—
        run_module = importlib.import_module(f'{module_path}.scripts.run_full_test')
        
        # æ„å»ºå‚æ•°
        args = argparse.Namespace(
            dataset=dataset,
            metric=metric,
            **kwargs
        )
        
        # è°ƒç”¨ main å‡½æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(run_module, 'main'):
            run_module.main(args)
        else:
            print(f"âš ï¸ Module {module_path}.scripts.run_full_test has no 'main' function")
            print(f"   Please run directly: python -m {module_path}.scripts.run_full_test --help")
            
    except (ImportError, ModuleNotFoundError) as e:
        print(f"âŒ Failed to import module: {module_path}")
        print(f"   Error: {e}")
        print(f"\n   Try running directly:")
        print(f"   cd {module_path.replace('.', '/')}")
        print(f"   python scripts/run_full_test.py --dataset {dataset} --metric {metric}")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description='LLM Training Data Evaluation - ç»Ÿä¸€å…¥å£',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é€‰é¡¹
    python -m common.evaluate --list
    
    # API Agent æ ¼å¼æ£€æŸ¥
    python -m common.evaluate -m api -d toolbench --metric format
    
    # GUI Agent é™æ€å¯æ‰§è¡Œæ€§
    python -m common.evaluate -m gui -d mind2web --metric static
    
    # Math ä»£ç æ‰§è¡ŒéªŒè¯
    python -m common.evaluate -m math -d lila --metric validity
        """
    )
    
    parser.add_argument('--list', '-l', action='store_true',
                        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡æ€å’Œæ•°æ®é›†')
    parser.add_argument('--modality', '-m', type=str,
                        choices=list(MODALITY_MODULES.keys()),
                        help='æ¨¡æ€: api, gui, math, image, video')
    parser.add_argument('--dataset', '-d', type=str,
                        help='æ•°æ®é›†åç§°')
    parser.add_argument('--metric', type=str,
                        help='è¯„ä¼°æŒ‡æ ‡')
    parser.add_argument('--max-samples', type=int, default=None,
                        help='æœ€å¤§æ ·æœ¬æ•°')
    parser.add_argument('--parallel', '-p', action='store_true',
                        help='ä½¿ç”¨å¹¶è¡Œæ¨¡å¼')
    parser.add_argument('--workers', '-w', type=int, default=None,
                        help='å¹¶è¡Œè¿›ç¨‹æ•°')
    
    args = parser.parse_args()
    
    if args.list:
        list_all()
        return
    
    if not args.modality:
        parser.print_help()
        print("\nâŒ Please specify --modality (-m)")
        sys.exit(1)
    
    if not args.dataset:
        parser.print_help()
        print("\nâŒ Please specify --dataset (-d)")
        sys.exit(1)
    
    if not args.metric:
        parser.print_help()
        print("\nâŒ Please specify --metric")
        sys.exit(1)
    
    # æ„å»º kwargs
    kwargs = {
        'max_samples': args.max_samples,
        'parallel': args.parallel,
        'workers': args.workers,
    }
    # ç§»é™¤ None å€¼
    kwargs = {k: v for k, v in kwargs.items() if v is not None}
    
    run_evaluation(args.modality, args.dataset, args.metric, **kwargs)


if __name__ == '__main__':
    main()
