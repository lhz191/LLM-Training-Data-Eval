#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ToolBench 常量定义
"""

# =============================================================================
# LLM 配置（用于 LLM Judge）
# =============================================================================

LLM_API_KEY = 'sk-o0QqcwC8XNHU6gGT7CYdMSQGJQQMtjKJSqw6K9G21IaoOElt'
LLM_BASE_URL = 'http://35.220.164.252:3888/v1/'
LLM_MODEL = 'gpt-4.1'


# =============================================================================
# LLM Judge Prompt 模板
# =============================================================================

DERIVABILITY_PROMPT = """你是一个数据质量评估专家。请判断以下 Agent 最终答案是否可以从 API 响应中推导出来。

【API 响应】
{api_responses}

【最终答案】
{final_answer}

请判断：最终答案中的关键信息是否能在 API 响应中找到支持？是否存在"编造"或"幻觉"的内容？

判断标准：
- 只要答案如实反映了 API 响应的内容，就应该判定为 derivable=true
- 如果 API 返回空结果，答案如实说明"没有数据"也是正确的
- 只有当答案包含 API 响应中完全不存在的信息时，才判定为 derivable=false

请以 JSON 格式输出：
```json
{{
    "derivable": true/false,
    "reason": "简要说明判断理由"
}}
```

只输出 JSON，不要其他内容。"""


RELEVANCE_PROMPT = """你是一个数据质量评估专家。请判断以下 Agent 最终答案是否正确回答了用户的查询。

【用户查询】
{query}

【最终答案】
{final_answer}

请判断：最终答案是否回应了用户的问题？

判断标准：
- 只要答案针对用户的问题给出了相关回应，就应该判定为 relevant=true
- 如果查询的数据不存在，答案如实说明"没有数据"也算正确回答
- 只有当答案完全偏题、答非所问时，才判定为 relevant=false

请以 JSON 格式输出：
```json
{{
    "relevant": true/false,
    "reason": "简要说明判断理由"
}}
```

只输出 JSON，不要其他内容。"""
