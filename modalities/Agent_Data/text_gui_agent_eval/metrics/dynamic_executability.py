#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dynamic Executability æŒ‡æ ‡ - GUI Agent åŠ¨æ€å¯æ‰§è¡Œæ€§æ£€æŸ¥

åœ¨çœŸå®ç½‘ç«™ä¸Šæ‰§è¡Œ GUI Agent æ•°æ®é›†æ ·æœ¬çš„æ“ä½œï¼š
- åæ ‡å®šä½æˆåŠŸç‡ï¼šä½¿ç”¨ bounding_box åæ ‡èƒ½å¦å®šä½åˆ°ç›®æ ‡å…ƒç´ 
- å±æ€§å®šä½æˆåŠŸç‡ï¼šä½¿ç”¨ tag/class/id ç­‰å±æ€§èƒ½å¦å®šä½åˆ°ç›®æ ‡å…ƒç´ 
- æ‰§è¡ŒæˆåŠŸç‡ï¼šæ“ä½œèƒ½å¦æˆåŠŸæ‰§è¡Œ

ä½¿ç”¨æ–¹å¼:
    from metrics import compute_dynamic_executability
    from loaders import Mind2WebLoader
    from mind2web_executor import Mind2WebDynamicChecker
    
    loader = Mind2WebLoader('/path/to/mind2web/data')
    checker = Mind2WebDynamicChecker(headless=False)
    
    results = compute_dynamic_executability(
        data_iterator=loader.iterate(),
        dynamic_checker=checker,
        dataset_name='Mind2Web',
        output_file='dynamic_executability_results.json'
    )
"""

import json
import time
from datetime import datetime
from typing import Optional, Iterator, Dict, List, Any

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_types import Record
from text_gui_executor import DynamicExecutabilityChecker


def compute_dynamic_executability(
    data_iterator: Iterator[Record],
    dynamic_checker: DynamicExecutabilityChecker,
    dataset_name: str = "unknown",
    output_file: Optional[str] = None,
    max_samples: Optional[int] = None,
    progress_interval: int = 1,
    execute: bool = True,
) -> Dict[str, Any]:
    """
    è®¡ç®—åŠ¨æ€å¯æ‰§è¡Œæ€§æŒ‡æ ‡
    
    Args:
        data_iterator: Record è¿­ä»£å™¨
        dynamic_checker: åŠ¨æ€å¯æ‰§è¡Œæ€§æ£€æŸ¥å™¨
        dataset_name: æ•°æ®é›†åç§°
        output_file: ç»“æœè¾“å‡ºæ–‡ä»¶
        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        progress_interval: è¿›åº¦æ˜¾ç¤ºé—´éš”
        execute: æ˜¯å¦æ‰§è¡Œæ“ä½œï¼ˆé»˜è®¤ Trueï¼‰
    
    Returns:
        ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
        - coord_rate: åæ ‡å®šä½æˆåŠŸç‡
        - attr_rate: å±æ€§å®šä½æˆåŠŸç‡
        - exec_rate: æ‰§è¡ŒæˆåŠŸç‡
        - è¯¦ç»†çš„ record å’Œ action çº§åˆ«ç»“æœ
    """
    print("=" * 70)
    print("Dynamic Executability Evaluation")
    print("=" * 70)
    print(f"æ•°æ®é›†: {dataset_name}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ‰§è¡Œæ¨¡å¼: {'æ‰§è¡Œæ“ä½œ' if execute else 'ä»…éªŒè¯'}")
    print()
    
    start_time = time.time()
    
    # Record çº§åˆ«ç»Ÿè®¡
    total_records = 0
    records_with_errors = 0
    records_with_warnings = 0
    
    # Action çº§åˆ«ç»Ÿè®¡
    total_actions = 0
    coord_success = 0
    attr_success = 0
    exec_success = 0
    
    # è¯¦ç»†ç»“æœ
    record_results = []
    error_records = []
    
    for record in data_iterator:
        if max_samples and total_records >= max_samples:
            break
        
        total_records += 1
        
        # æ£€æŸ¥åŠ¨æ€å¯æ‰§è¡Œæ€§
        errors, warnings, stats = dynamic_checker.check(
            record, 
            execute=execute,
        )
        
        # Record çº§åˆ«ç»Ÿè®¡
        if errors:
            records_with_errors += 1
            error_records.append({
                'sample_id': record.sample_id,
                'website': record.website,
                'errors': errors,
            })
        if warnings:
            records_with_warnings += 1
        
        # Action çº§åˆ«ç»Ÿè®¡
        total_actions += stats.get('total_actions', 0)
        coord_success += stats.get('coords_success', 0)
        attr_success += stats.get('attrs_success', 0)
        exec_success += stats.get('executed_actions', 0)
        
        # è®°å½•è¯¦ç»†ç»“æœ
        record_results.append({
            'sample_id': record.sample_id,
            'website': record.website,
            'url': stats.get('url', ''),
            'total_actions': stats.get('total_actions', 0),
            'coords_success': stats.get('coords_success', 0),
            'attrs_success': stats.get('attrs_success', 0),
            'executed_actions': stats.get('executed_actions', 0),
            'coord_rate': stats.get('coords_rate', 0.0),
            'attr_rate': stats.get('attrs_rate', 0.0),
            'exec_rate': stats.get('execution_rate', 0.0),
            'errors': errors,
            'warnings': warnings,
            'action_results': stats.get('action_results', []),
        })
        
        # è¿›åº¦
        if progress_interval and total_records % progress_interval == 0:
            elapsed = time.time() - start_time
            rate = total_records / elapsed if elapsed > 0 else 0
            curr_coord_rate = coord_success / total_actions if total_actions > 0 else 0
            curr_attr_rate = attr_success / total_actions if total_actions > 0 else 0
            curr_exec_rate = exec_success / total_actions if total_actions > 0 else 0
            print(f"\n  [{total_records:,}] {rate:.2f} æ¡/ç§’")
            print(f"    åæ ‡å®šä½: {coord_success}/{total_actions} ({curr_coord_rate:.1%})")
            print(f"    å±æ€§å®šä½: {attr_success}/{total_actions} ({curr_attr_rate:.1%})")
            if execute:
                print(f"    æ‰§è¡ŒæˆåŠŸ: {exec_success}/{total_actions} ({curr_exec_rate:.1%})")
    
    elapsed = time.time() - start_time
    
    # è®¡ç®—æ€»ä½“æˆåŠŸç‡
    coord_rate = coord_success / total_actions if total_actions > 0 else 0.0
    attr_rate = attr_success / total_actions if total_actions > 0 else 0.0
    exec_rate = exec_success / total_actions if total_actions > 0 else 0.0
    
    # ç»“æœ
    results = {
        'dataset': dataset_name,
        'timestamp': datetime.now().isoformat(),
        'elapsed_seconds': elapsed,
        'execute_mode': execute,
        
        # Record çº§åˆ«ç»Ÿè®¡
        'total_records': total_records,
        'records_with_errors': records_with_errors,
        'records_with_warnings': records_with_warnings,
        
        # Action çº§åˆ«ç»Ÿè®¡
        'total_actions': total_actions,
        'coord_success': coord_success,
        'attr_success': attr_success,
        'exec_success': exec_success,
        
        # æˆåŠŸç‡
        'coord_rate': coord_rate,
        'attr_rate': attr_rate,
        'exec_rate': exec_rate,
        
        # è¯¦ç»†ç»“æœ
        'record_results': record_results,
        'error_records': error_records,
    }
    
    # ä¿å­˜ç»“æœ
    if output_file:
        output_dir = os.path.dirname(output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
        # ä¿å­˜ summary.txt
        summary_file = output_file.replace('.json', '_summary.txt')
        _save_summary_log(results, summary_file, elapsed, output_file, execute)
    
    # æ‰“å°æ‘˜è¦
    _print_summary(results, elapsed, execute)
    
    return results


def _save_summary_log(results: Dict[str, Any], summary_file: str, elapsed: float, json_file: str, execute: bool):
    """ä¿å­˜ç®€æ´çš„ summary.txt æ—¥å¿—"""
    lines = []
    lines.append("=" * 60)
    lines.append(f"Dynamic Executability è¯„ä¼°æ±‡æ€» - {results.get('dataset', 'Unknown')}")
    lines.append("=" * 60)
    lines.append(f"æ—¶é—´: {results.get('timestamp', 'N/A')}")
    lines.append(f"è€—æ—¶: {elapsed:.1f} ç§’")
    lines.append(f"æ‰§è¡Œæ¨¡å¼: {'æ‰§è¡Œæ“ä½œ' if execute else 'ä»…éªŒè¯'}")
    lines.append("")
    
    lines.append("ã€Record çº§åˆ«ã€‘")
    lines.append(f"  æ€» Record æ•°: {results.get('total_records', 0)}")
    lines.append(f"  æœ‰é”™è¯¯: {results.get('records_with_errors', 0)}")
    lines.append(f"  æœ‰è­¦å‘Š: {results.get('records_with_warnings', 0)}")
    lines.append("")
    
    lines.append("ã€Action çº§åˆ«ã€‘")
    lines.append(f"  æ€» Action æ•°: {results.get('total_actions', 0)}")
    lines.append("")
    
    lines.append("ã€åŠ¨æ€å¯æ‰§è¡Œæ€§æŒ‡æ ‡ã€‘")
    lines.append(f"  coord_rate: {results.get('coord_rate', 0):.4f}")
    lines.append(f"  coord_success: {results.get('coord_success', 0)}")
    lines.append(f"  attr_rate: {results.get('attr_rate', 0):.4f}")
    lines.append(f"  attr_success: {results.get('attr_success', 0)}")
    if execute:
        lines.append(f"  exec_rate: {results.get('exec_rate', 0):.4f}")
        lines.append(f"  exec_success: {results.get('exec_success', 0)}")
    lines.append("")
    
    lines.append("=" * 60)
    lines.append("ã€å…³é”®æŒ‡æ ‡æ±‡æ€»ã€‘")
    lines.append("=" * 60)
    coord_rate = results.get('coord_rate', 0)
    attr_rate = results.get('attr_rate', 0)
    exec_rate = results.get('exec_rate', 0)
    lines.append(f"  ğŸ“ åæ ‡å®šä½æˆåŠŸç‡: {coord_rate:.2%}")
    lines.append(f"  ğŸ·ï¸ å±æ€§å®šä½æˆåŠŸç‡: {attr_rate:.2%}")
    if execute:
        lines.append(f"  âš¡ æ‰§è¡ŒæˆåŠŸç‡: {exec_rate:.2%}")
    lines.append("")
    
    # æŒ‰ç½‘ç«™ç»Ÿè®¡
    website_stats = {}
    for r in results.get('record_results', []):
        site = r.get('website') or 'unknown'
        if site not in website_stats:
            website_stats[site] = {
                'records': 0,
                'actions': 0,
                'coord': 0,
                'attr': 0,
                'exec': 0,
            }
        website_stats[site]['records'] += 1
        website_stats[site]['actions'] += r.get('total_actions', 0)
        website_stats[site]['coord'] += r.get('coords_success', 0)
        website_stats[site]['attr'] += r.get('attrs_success', 0)
        website_stats[site]['exec'] += r.get('executed_actions', 0)
    
    if len(website_stats) > 1:
        lines.append("ã€æŒ‰ç½‘ç«™ç»Ÿè®¡ (Top 10)ã€‘")
        sorted_sites = sorted(website_stats.items(), key=lambda x: -x[1]['records'])
        for site, stats in sorted_sites[:10]:
            a = stats['actions']
            if a > 0:
                coord_r = stats['coord'] / a
                attr_r = stats['attr'] / a
                exec_r = stats['exec'] / a
                if execute:
                    lines.append(f"  {site}: {stats['records']} records, "
                                f"åæ ‡ {coord_r:.0%}, å±æ€§ {attr_r:.0%}, æ‰§è¡Œ {exec_r:.0%}")
                else:
                    lines.append(f"  {site}: {stats['records']} records, "
                                f"åæ ‡ {coord_r:.0%}, å±æ€§ {attr_r:.0%}")
        if len(sorted_sites) > 10:
            lines.append(f"  ... è¿˜æœ‰ {len(sorted_sites) - 10} ä¸ªç½‘ç«™")
        lines.append("")
    
    lines.append("=" * 60)
    lines.append(f"è¯¦ç»†ç»“æœ: {json_file}")
    lines.append("=" * 60)
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    print(f"æ±‡æ€»å·²ä¿å­˜åˆ°: {summary_file}")


def _print_summary(results: Dict[str, Any], elapsed: float, execute: bool):
    """æ‰“å°è¯„ä¼°æ‘˜è¦"""
    print()
    print("=" * 70)
    print(f"è¯„ä¼°å®Œæˆï¼è€—æ—¶ {elapsed:.1f} ç§’")
    print("=" * 70)
    print()
    print(f"ã€Record çº§åˆ«ã€‘")
    print(f"  æ€» Record æ•°: {results['total_records']:,}")
    print(f"  æœ‰é”™è¯¯: {results['records_with_errors']:,}")
    print(f"  æœ‰è­¦å‘Š: {results['records_with_warnings']:,}")
    print()
    print(f"ã€Action çº§åˆ«ã€‘")
    print(f"  æ€» Action æ•°: {results['total_actions']:,}")
    print()
    print(f"ã€åŠ¨æ€å¯æ‰§è¡Œæ€§ã€‘")
    print(f"  åæ ‡å®šä½æˆåŠŸç‡: {results['coord_success']:,}/{results['total_actions']:,} "
          f"({results['coord_rate']:.2%})")
    print(f"  å±æ€§å®šä½æˆåŠŸç‡: {results['attr_success']:,}/{results['total_actions']:,} "
          f"({results['attr_rate']:.2%})")
    if execute:
        print(f"  æ‰§è¡ŒæˆåŠŸç‡: {results['exec_success']:,}/{results['total_actions']:,} "
              f"({results['exec_rate']:.2%})")
    print()
    
    # æŒ‰ç½‘ç«™ç»Ÿè®¡
    website_stats = {}
    for r in results['record_results']:
        site = r.get('website') or 'unknown'
        if site not in website_stats:
            website_stats[site] = {
                'records': 0,
                'actions': 0,
                'coord': 0,
                'attr': 0,
                'exec': 0,
            }
        website_stats[site]['records'] += 1
        website_stats[site]['actions'] += r.get('total_actions', 0)
        website_stats[site]['coord'] += r.get('coords_success', 0)
        website_stats[site]['attr'] += r.get('attrs_success', 0)
        website_stats[site]['exec'] += r.get('executed_actions', 0)
    
    if len(website_stats) > 1:
        print(f"ã€æŒ‰ç½‘ç«™ç»Ÿè®¡ã€‘")
        sorted_sites = sorted(website_stats.items(), key=lambda x: -x[1]['records'])
        for site, stats in sorted_sites[:10]:
            a = stats['actions']
            if a > 0:
                coord_r = stats['coord'] / a
                attr_r = stats['attr'] / a
                exec_r = stats['exec'] / a
                if execute:
                    print(f"  {site}: {stats['records']} records, "
                          f"åæ ‡ {coord_r:.0%}, å±æ€§ {attr_r:.0%}, æ‰§è¡Œ {exec_r:.0%}")
                else:
                    print(f"  {site}: {stats['records']} records, "
                          f"åæ ‡ {coord_r:.0%}, å±æ€§ {attr_r:.0%}")
        if len(sorted_sites) > 10:
            print(f"  ... è¿˜æœ‰ {len(sorted_sites) - 10} ä¸ªç½‘ç«™")
        print()


# =============================================================================
# å‘½ä»¤è¡Œå…¥å£
# =============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åŠ¨æ€å¯æ‰§è¡Œæ€§æŒ‡æ ‡è¯„ä¼°")
    parser.add_argument("--dataset", type=str, required=True, 
                        choices=["mind2web", "weblinx"],
                        help="æ•°æ®é›†åç§°")
    parser.add_argument("--data-path", type=str, default=None,
                        help="æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--max-samples", type=int, default=None,
                        help="æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    parser.add_argument("--output", type=str, default=None,
                        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--show", action="store_true",
                        help="æ˜¾ç¤ºæµè§ˆå™¨çª—å£")
    parser.add_argument("--no-execute", action="store_true",
                        help="ä»…éªŒè¯ä¸æ‰§è¡Œæ“ä½œ")
    parser.add_argument("--progress-interval", type=int, default=1,
                        help="è¿›åº¦æ˜¾ç¤ºé—´éš”")
    
    args = parser.parse_args()
    
    # æ ¹æ®æ•°æ®é›†é€‰æ‹© loader å’Œ checker
    if args.dataset == "mind2web":
        from loaders import Mind2WebLoader
        from mind2web_executor import Mind2WebDynamicChecker
        
        data_path = args.data_path or '/mnt/petrelfs/liuhaoze/datasets/Agent_Data/Mind2Web/data'
        loader = Mind2WebLoader(data_path)
        loader.load()
        
        checker = Mind2WebDynamicChecker(
            headless=not args.show,
        )
        dataset_name = "Mind2Web"
        
    elif args.dataset == "weblinx":
        # TODO: WebLINX checker è¿˜æœªå®ç°
        raise NotImplementedError("WebLINX dynamic checker not implemented yet")
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶
    output_file = args.output
    if output_file is None:
        output_file = f"results/{args.dataset}/dynamic_executability_results.json"
    
    # è¿è¡Œè¯„ä¼°
    results = compute_dynamic_executability(
        data_iterator=loader.iterate(),
        dynamic_checker=checker,
        dataset_name=dataset_name,
        output_file=output_file,
        max_samples=args.max_samples,
        progress_interval=args.progress_interval,
        execute=not args.no_execute,
    )
